{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torchvision\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from read_all_as_df import read_all_as_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "sns.set_style(\"darkgrid\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PATH = os.path.join(\"runs\", \"keep\", \"paper_runs\")\n",
    "\n",
    "df_runs = read_all_as_df(PATH)\n",
    "df_runs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(*df_runs[\"run_name\"].unique(), sep=\", \")\n",
    "print(*df_runs[\"metric\"].unique(), sep=\", \")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_runs[\"original_run_name\"] = df_runs[\"run_name\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def parse_run_name(name: str):\n",
    "    parts = name.split(\"_\")[:-1]\n",
    "    if len(parts) > 1:\n",
    "        parts[0] = parts[0].upper()\n",
    "        parts[1] = parts[1][0].upper() + parts[1][1:]\n",
    "    else:\n",
    "        parts[0] = parts[0][0].upper() + parts[0][1:]\n",
    "    if len(parts) > 2:\n",
    "        parts[2] = parts[2].upper()\n",
    "    return \" \".join(parts)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_runs[\"run_name\"] = (\n",
    "    df_runs[\"original_run_name\"].map(parse_run_name)\n",
    ")\n",
    "df_runs[\"agent_type\"] = df_runs[\"run_name\"].str.split(\" \").apply(lambda l: l[0]).astype(\"category\")\n",
    "df_runs[\"network_type\"] = df_runs[\"run_name\"].str.split(\" \").apply(lambda l: l[min(len(l) - 1, 1)]).astype(\"category\")\n",
    "df_runs[\"has_lstm\"] = df_runs[\"run_name\"].str.contains(\"LSTM\")\n",
    "df_runs[\"memory\"] = df_runs[\"agent\"].map(lambda a: \"Reward Prioritized Memory\" if a == \"pursuer_1\" else \"Normal Memory\")\n",
    "\n",
    "df_runs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Truncate steps\n",
    "min_max_steps = min(df_runs[\"original_run_name\"].str.split(\"_\").map(lambda l: int(l[-1][:-3])))\n",
    "df_runs.query(\"step <= @min_max_steps\", inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(*df_runs[\"run_name\"].unique(), sep=\", \")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# QNN vs A2C vs DDPG vs Controls vs Random"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "to_plot = (\n",
    "    df_runs.query(\"metric == 'test_total_reward'\")\n",
    "    .query(\"agent_type != 'CPT'\")\n",
    "    .query(\"run_name != 'DDPG Distance CPT'\")\n",
    ")\n",
    "to_plot[\"agent_type\"] = to_plot[\"agent_type\"].cat.remove_unused_categories()\n",
    "\n",
    "means = to_plot.groupby(by=\"agent_type\")[\"value\"].mean()\n",
    "print(means)\n",
    "\n",
    "to_plot[\"smoothed_value\"] = to_plot[\"value\"].ewm(alpha=1 - 0.65).mean()\n",
    "plot = sns.lineplot(data=to_plot, x=\"step\", y=\"smoothed_value\", hue=\"agent_type\")\n",
    "plot.set_xlabel(\"Episode\")\n",
    "plot.set_ylabel(\"Reward\")\n",
    "plot.set_title(\"Rewards by Agent\")\n",
    "plot.legend(title=\"Agent Type\")\n",
    "plot.figure.savefig(\"rewards-by-agent.eps\", format=\"eps\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RPM vs Normal Memory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "to_plot = (\n",
    "    df_runs.query(\"metric == 'loss' or metric == 'actor_loss'\")\n",
    "    .query(\"agent_type != 'CPT'\")\n",
    "    .query(\"run_name != 'DDPG Distance CPT'\")\n",
    ")\n",
    "to_plot[\"agent_type\"] = to_plot[\"agent_type\"].cat.remove_unused_categories()\n",
    "\n",
    "to_plot[\"Smoothed Loss\"] = (\n",
    "    to_plot.groupby(by=[\"agent_type\", \"memory\"])[\"value\"]\n",
    "    .ewm(alpha=1 - 0.999)\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .set_index(\"level_2\")\n",
    "    .drop(columns=[\"agent_type\", \"memory\"])\n",
    ")\n",
    "\n",
    "for type_ in to_plot[\"agent_type\"].unique():\n",
    "    plot = sns.lineplot(\n",
    "        data=to_plot.query(\"agent_type == @type_\"),\n",
    "        x=\"step\",\n",
    "        y=\"Smoothed Loss\",\n",
    "        hue=\"memory\",\n",
    "    )\n",
    "    plot.set_xlabel(\"Episode\")\n",
    "    plot.set_ylabel(\"(Actor) Loss\")\n",
    "    plot.set_title(\"Loss by Memory Type\")\n",
    "    plot.legend(title=\"Memory Type\")\n",
    "    plot.figure.savefig(f\"loss-by-memory-{type_}.eps\", format=\"eps\")\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple vs Distance vs Simple LSTM vs Distance LSTM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "to_plot = (\n",
    "    df_runs.query(\"metric == 'test_total_reward'\")\n",
    "    .query(\"agent_type != 'CPT'\")\n",
    "    .query(\"run_name != 'DDPG Distance CPT'\")\n",
    "    .query(\"agent_type != 'Controls'\")\n",
    "    .query(\"agent_type != 'Random'\")\n",
    ")\n",
    "to_plot[\"agent_type\"] = to_plot[\"agent_type\"].cat.remove_unused_categories()\n",
    "to_plot[\"network_type\"] = to_plot[\"network_type\"].cat.remove_unused_categories()\n",
    "\n",
    "to_plot[\"type\"] = to_plot[\"agent_type\"].astype(str) + \" \" + to_plot[\"network_type\"].astype(str) + to_plot[\"has_lstm\"].map(\n",
    "    lambda lstm: \" LSTM\" if lstm else \"\"\n",
    ")\n",
    "\n",
    "means = to_plot.groupby(by=[\"type\"])[\"value\"].mean()\n",
    "print(means)\n",
    "to_plot[\"smoothed_value\"] = to_plot[\"value\"].ewm(alpha=1 - 0.999).mean()\n",
    "\n",
    "for type_ in to_plot[\"agent_type\"].unique():\n",
    "    plot = sns.lineplot(\n",
    "        data=to_plot.query(\"agent_type == @type_\"),\n",
    "        x=\"step\",\n",
    "        y=\"smoothed_value\",\n",
    "        hue=\"type\",\n",
    "    )\n",
    "    plot.set_xlabel(\"Episode\")\n",
    "    plot.set_ylabel(\"Reward\")\n",
    "    plot.set_title(\"Rewards by Agent and Network Type\")\n",
    "    plot.legend(title=\"Architecture\")\n",
    "    plot.figure.savefig(f\"rewards-by-architecture-{type_}.eps\", format=\"eps\")\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DDPG vs CPT DDPG"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "to_plot = (\n",
    "    df_runs.query(\"metric == 'test_total_reward'\")\n",
    "    .query(\"run_name == 'DDPG Distance CPT' or run_name == 'DDPG Distance'\")\n",
    ")\n",
    "to_plot[\"run_name\"] = to_plot[\"run_name\"].cat.remove_unused_categories()\n",
    "\n",
    "means = to_plot.groupby(by=\"run_name\")[\"value\"].mean()\n",
    "print(means)\n",
    "\n",
    "to_plot[\"smoothed_value\"] = to_plot[\"value\"].ewm(alpha=1 - 0.999).mean()\n",
    "plot = sns.lineplot(data=to_plot, x=\"step\", y=\"smoothed_value\", hue=\"run_name\")\n",
    "plot.set_xlabel(\"Episode\")\n",
    "plot.set_ylabel(\"Reward\")\n",
    "plot.set_title(\"Controls Policy Trainer DDPG vs DDPG Reward\")\n",
    "plot.legend(title=\"Agent Type\")\n",
    "plot.figure.savefig(\"rewards-by-agent-cpt.eps\", format=\"eps\");"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "to_plot = (\n",
    "    df_runs.query(\"metric == 'actor_loss'\")\n",
    "    .query(\"run_name == 'DDPG Distance CPT' or run_name == 'DDPG Distance'\")\n",
    ")\n",
    "to_plot[\"run_name\"] = to_plot[\"run_name\"].cat.remove_unused_categories()\n",
    "\n",
    "to_plot[\"smoothed_value\"] = to_plot[\"value\"]\n",
    "plot = sns.lineplot(data=to_plot, x=\"step\", y=\"smoothed_value\", hue=\"run_name\")\n",
    "plot.set_xlabel(\"Episode\")\n",
    "plot.set_ylabel(\"(Actor) Loss\")\n",
    "plot.set_title(\"Controls Policy Trainer DDPG vs DDPG Loss\")\n",
    "plot.legend(title=\"Agent Type\")\n",
    "plot.figure.savefig(\"loss-by-agent-cpt.eps\", format=\"eps\");"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
